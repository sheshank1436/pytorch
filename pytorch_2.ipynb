{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOblu2b813QJh8pc5ZMtKHU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheshank1436/pytorch/blob/master/pytorch_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BACg39nXcXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSIOUPlnXksC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=MNIST(root='C:\\\\Users\\\\shkatta\\\\Desktop\\\\AI\\\\csv files',download=True)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EwDQ1VKXkun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7cac58a2-329e-422a-ef48-f228a1c4d92e"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: C:\\Users\\shkatta\\Desktop\\AI\\csv files\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEqasPEyXkxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e06a122-2d25-4275-d125-bdae6cdd0b4d"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pr0kfc3Xk0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset=MNIST(root='C:\\\\Users\\\\shkatta\\\\Desktop\\\\AI\\\\csv files',train=False)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrWwWaVCSgdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "394ecbd8-4afc-4740-81ef-3793ae54fb03"
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7F5FE50AA7F0>, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDSkrgg-Smjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SzT9DiOSxTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d15dc432-45fd-41dd-f120-c2e05a4f7f77"
      },
      "source": [
        "image,label=dataset[0]\n",
        "plt.imshow(image,cmap='gray')\n",
        "print(\"label\",label)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM121ipHTFWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from the above we can see the images but there size is very small\n",
        "#one problem with PyTorch is it doesn't know how to work with images\n",
        "#we need to convert them to tensors\n",
        "#we can do this by specifying the transform\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzYNJIqiUEzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=MNIST(root='C:\\\\Users\\\\shkatta\\\\Desktop\\\\AI\\\\csv files',train=True,transform=transforms.ToTensor())"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3ee8YuhUaCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6128b641-1cb6-411e-888e-8e0a39d2c243"
      },
      "source": [
        "#image is gray scale so it has only 1-dimension\n",
        "image,label=dataset[0]\n",
        "print(image.shape,label)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28]) 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZRI9nAqUkC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "407e95d4-35b9-4ec7-dc75-e818c3229667"
      },
      "source": [
        "#let us print some values inside the image\n",
        "#in the below values 0 represents black and 1 represents white\n",
        "#values in btw 0 and 1 represent different shades of gray\n",
        "print(image[:,10:17,17:22])\n",
        "print(torch.max(image),torch.min(image))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0039, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4667, 0.0980, 0.0000, 0.0000, 0.0000],\n",
            "         [0.9922, 0.5882, 0.1059, 0.0000, 0.0000],\n",
            "         [0.9882, 0.9922, 0.7333, 0.0000, 0.0000]]])\n",
            "tensor(1.) tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g76-cCmwVSI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "742d474f-19ce-4b77-916a-9289eabff562"
      },
      "source": [
        "#now lets plot some part of the image and see what does it contain\n",
        "plt.imshow(image[0,10:115,17:222],cmap=\"gray\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5fe518ba20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW-g8KnvXTsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41b59143-ff65-4338-ed13-79770370363e"
      },
      "source": [
        "#lets divide our training data into train and validation \n",
        "#we will split the data randomly because the train data might be ordered based on target values\n",
        "from torch.utils.data import random_split\n",
        "train_ds,val_ds=random_split(dataset,[50000,10000])\n",
        "print(len(train_ds),len(val_ds))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M80ydaeFaUKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from the linear regression which we created earlier we know that we need to have the data present in the form of batches\n",
        "#for that we use a dataloader\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AxOfX22b_W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=128\n",
        "tr_load=DataLoader(train_ds,batch_size=batch_size,shuffle=True)\n",
        "val_load=DataLoader(val_ds,batch_size=batch_size)\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIylva9ScQbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now we need to create the model \n",
        "#logistic regression is almost similar to the linear regression model\n",
        "#nn.linear expect the input to be in the form of a vector\n",
        "# so we flatten the images of size 1*28*28 to 784(28*28) before passing it to the model\n",
        "#the output of each image is a vector of size 10 where each element determines the prob of each class\n",
        "#the element having  highest prob will be the predicted output\n",
        "import torch.nn as nn\n",
        "input_size=28*28\n",
        "num_classes=10\n",
        "#logistic regression model\n",
        "model=nn.Linear(input_size,num_classes)\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc9rmw7nftlE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02b76e59-afda-48bd-b363-a327a3735886"
      },
      "source": [
        "print(model.weight.shape)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra72R87dhWON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eed94a0c-0c51-4924-d196-ea16a14ab2ec"
      },
      "source": [
        "print(model.bias.shape)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XlTSMJVheEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "44e828dc-964e-4740-bba8-b677091d95c0"
      },
      "source": [
        "#now let us make some predictions\n",
        "#here in the img shape first dimension represent the batchsize\n",
        "for img,label in tr_load:\n",
        "  print(label)\n",
        "  print(img.shape)\n",
        "  out=model(img)\n",
        "  print(out)\n",
        "  break"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 3, 9, 6, 5, 6, 7, 9, 2, 1, 4, 6, 7, 6, 7, 2, 8, 1, 6, 3, 3, 3, 5, 9,\n",
            "        0, 0, 4, 2, 0, 9, 7, 3, 5, 5, 7, 4, 8, 8, 5, 3, 0, 4, 4, 4, 3, 6, 2, 0,\n",
            "        9, 6, 4, 8, 0, 3, 6, 0, 8, 5, 3, 4, 8, 1, 0, 2, 5, 5, 5, 2, 6, 6, 5, 5,\n",
            "        1, 2, 0, 8, 5, 9, 6, 1, 5, 0, 5, 5, 5, 9, 7, 4, 9, 2, 7, 3, 7, 1, 7, 0,\n",
            "        0, 0, 6, 7, 2, 8, 5, 2, 7, 8, 9, 9, 4, 8, 1, 9, 9, 7, 8, 2, 3, 3, 4, 0,\n",
            "        5, 8, 1, 3, 0, 6, 3, 3])\n",
            "torch.Size([128, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-6d7c549d76d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [3584 x 28], m2: [784 x 10] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFX0UvgsiJN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#in the above error occured because the model expects the input to have one shape and it got some other shape\n",
        "#the point is we need to flatten the inputs before feeding them to the model\n",
        "#OUR Images are of shape 28*28 but we need to have a vector of size 784\n",
        "#array will be in them form of a matrix with n dimensions\n",
        "#vector will be in the form of a list\n",
        "#Now the solution to this problem is we need to use the .reshape function of tensors to convert the images into vectors\n",
        "#To include this additional functionality within our model, we need to define a custom model\n",
        "#the way to define the custom model in pytorch is by using the nn.Module\n",
        "#firstline is the syntax for extending the class in pytorch\n",
        "#line 2 is constructor\n",
        "#line 3 is called when you instantiate the class or when you create the object of the class\n",
        "# we give -1 in reshape function so the function will predict what should be the value in that place\n",
        "\n",
        "class MnistModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear=nn.Linear(input_size,num_classes)\n",
        "  def forward(self,xb):\n",
        "    xb=xb.reshape(-1,784)\n",
        "    out=self.linear(xb)\n",
        "    return out\n",
        "    \n",
        "model=MnistModel()"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y32GThyiJQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f7585a8-7a79-4515-97a1-63d456e2322e"
      },
      "source": [
        "print(model.linear.weight.shape)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pklC6GQhiJS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1224315-7f4d-4e8b-f3f6-4a3d90a54d81"
      },
      "source": [
        "print(model.linear.bias.shape)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG1kCQA9iJVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "1d2b1a6c-86d2-4eb7-d764-717599db8b98"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-2.8194e-02, -7.6404e-04,  9.8564e-05,  ..., -1.7038e-02,\n",
              "          -1.1669e-02, -1.4908e-02],\n",
              "         [ 3.5041e-02,  3.2869e-02, -2.3298e-02,  ...,  2.8538e-03,\n",
              "           1.7733e-02,  3.5155e-02],\n",
              "         [-1.4683e-02,  1.2461e-02, -1.6134e-02,  ..., -3.2839e-02,\n",
              "           1.7883e-02,  2.4404e-02],\n",
              "         ...,\n",
              "         [-3.7150e-03, -2.6605e-02,  2.7084e-02,  ...,  3.5290e-02,\n",
              "           3.0128e-03,  3.0019e-02],\n",
              "         [-3.0568e-02,  2.6771e-02,  3.4347e-02,  ..., -2.8651e-02,\n",
              "          -1.4811e-02, -3.4193e-02],\n",
              "         [ 3.3422e-02, -4.9376e-03,  2.8521e-02,  ..., -2.2710e-02,\n",
              "          -3.9817e-03, -4.1283e-04]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0273,  0.0140,  0.0335, -0.0092, -0.0212,  0.0222, -0.0108,  0.0113,\n",
              "         -0.0172, -0.0237], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKsd48ipiJXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for img,label in tr_load:\n",
        "\n",
        "  out=model(img)\n",
        "  break"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPiRDrPf2YQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "350d8279-4c83-4f56-a0dc-b281f73e0ae2"
      },
      "source": [
        "out[0]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0175, -0.0056,  0.1120,  0.3575, -0.1476, -0.2937, -0.0612,  0.2531,\n",
              "        -0.3779, -0.2913], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTgT9ScJiJaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#From the above we can see that each output has 10 elements \n",
        "#we need to use exp to rescale the outputs \n",
        "exp=torch.exp(out[0])\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOX5umefiJcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d208367b-fa72-4dba-d84c-6332eb24b440"
      },
      "source": [
        "#From the above we can see that each output has 10 elements \n",
        "#But still the output elements are not in btw 0 and 1\n",
        "#when we sum all the values of the output it should be equal to 1\n",
        "#we can get that by performing the following function\n",
        "prb=exp/torch.sum(exp)\n",
        "\n",
        "prb"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1035, 0.1012, 0.1138, 0.1454, 0.0878, 0.0758, 0.0957, 0.1310, 0.0697,\n",
              "        0.0760], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXkWw2RLiJeq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06d9c715-b251-4201-a3bd-6f157bb72758"
      },
      "source": [
        "torch.sum(prb)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "185TNogyiJhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we can perform the above function on the whole data using the softmax function\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiVN8a3ViJjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "03f88255-9cfa-4310-fd1a-cc15bbb34791"
      },
      "source": [
        "#apply softmax for each output row\n",
        "#dim=1 because we apply softmax to image\n",
        "#dim=0 represents batch size\n",
        "probs=F.softmax(out,dim=1)\n",
        "print(\"sample probabilites \\n\", probs[:2].data)\n",
        "print(torch.sum(probs[0]).item())"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample probabilites \n",
            " tensor([[0.1035, 0.1012, 0.1138, 0.1454, 0.0878, 0.0758, 0.0957, 0.1310, 0.0697,\n",
            "         0.0760],\n",
            "        [0.0798, 0.0925, 0.1021, 0.1266, 0.0896, 0.0950, 0.1423, 0.1113, 0.0919,\n",
            "         0.0690]])\n",
            "0.9999998807907104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9YgtWcyJokY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d7e61ea2-cbe7-4e84-87b7-27f3a42813f0"
      },
      "source": [
        "for images,labels in tr_load:\n",
        "  print(images.shape)\n",
        "  outputs=model(images)\n",
        "  break\n",
        "print(outputs.shape)\n",
        "print(outputs[:2].data)\n",
        "\n"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 10])\n",
            "tensor([[-0.2462,  0.1198, -0.2730,  0.4348, -0.0394, -0.2031,  0.0377, -0.0082,\n",
            "          0.1137, -0.3590],\n",
            "        [-0.1171, -0.0539, -0.1581, -0.0420, -0.0230, -0.2561,  0.0794,  0.0702,\n",
            "         -0.0352, -0.2438]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkmna8vhA0-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first variable gives the max value from output 10 elements\n",
        "#second value will give its respective index\n",
        "max_probs,preds=torch.max(probs,dim=1)\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYBeSyJfBx_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b306172c-f4f9-4ec4-b28a-ffc6a0b9e7cb"
      },
      "source": [
        "max_probs"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1454, 0.1423, 0.1253, 0.1222, 0.1188, 0.1146, 0.1221, 0.1687, 0.1299,\n",
              "        0.1291, 0.1236, 0.1455, 0.1271, 0.1252, 0.1243, 0.1132, 0.1232, 0.1257,\n",
              "        0.1306, 0.1334, 0.1290, 0.1303, 0.1276, 0.1279, 0.1400, 0.1362, 0.1150,\n",
              "        0.1422, 0.1170, 0.1332, 0.1526, 0.1554, 0.1559, 0.1520, 0.1488, 0.1217,\n",
              "        0.1309, 0.1292, 0.1232, 0.1261, 0.1251, 0.1291, 0.1298, 0.1152, 0.1230,\n",
              "        0.1138, 0.1329, 0.1298, 0.1150, 0.1376, 0.1205, 0.1282, 0.1242, 0.1329,\n",
              "        0.1405, 0.1628, 0.1365, 0.1300, 0.1354, 0.1368, 0.1370, 0.1203, 0.1229,\n",
              "        0.1269, 0.1193, 0.1262, 0.1825, 0.1460, 0.1327, 0.1240, 0.1453, 0.1274,\n",
              "        0.1148, 0.1164, 0.1216, 0.1416, 0.1394, 0.1181, 0.1175, 0.1442, 0.1406,\n",
              "        0.1358, 0.1351, 0.1407, 0.1198, 0.1248, 0.1239, 0.1554, 0.1344, 0.1333,\n",
              "        0.1182, 0.1208, 0.1572, 0.1262, 0.1352, 0.1587, 0.1280, 0.1540, 0.1313,\n",
              "        0.1457, 0.1149, 0.1374, 0.1236, 0.1595, 0.1301, 0.1494, 0.1230, 0.1175,\n",
              "        0.1486, 0.1294, 0.1123, 0.1293, 0.1170, 0.1165, 0.1208, 0.1443, 0.1206,\n",
              "        0.1187, 0.1249, 0.1315, 0.1227, 0.1240, 0.1411, 0.1451, 0.1275, 0.1282,\n",
              "        0.1127, 0.1276], grad_fn=<MaxBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0luVZARBz_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ba1fac0d-dc1a-44e1-b94d-45e91cdce4e4"
      },
      "source": [
        "preds"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 6, 8, 2, 3, 7, 3, 3, 6, 1, 1, 7, 7, 8, 3, 8, 6, 6, 3, 3, 7, 3, 7, 7,\n",
              "        3, 7, 6, 7, 3, 7, 7, 7, 3, 1, 3, 7, 3, 7, 2, 7, 7, 6, 7, 7, 2, 4, 3, 7,\n",
              "        7, 7, 6, 7, 7, 7, 2, 3, 7, 6, 7, 3, 7, 6, 3, 7, 3, 3, 7, 1, 3, 3, 3, 3,\n",
              "        0, 7, 3, 3, 3, 7, 6, 1, 3, 7, 3, 7, 7, 7, 7, 6, 3, 7, 3, 1, 3, 7, 7, 3,\n",
              "        3, 3, 7, 3, 1, 3, 3, 7, 7, 3, 2, 6, 3, 3, 4, 6, 2, 7, 3, 7, 3, 3, 7, 0,\n",
              "        6, 7, 3, 7, 7, 3, 7, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zfkFQxiB4Y8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8d183c1c-7df7-4727-9f4f-9110119754ef"
      },
      "source": [
        "#actual outputs\n",
        "labels"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 8, 4, 1, 4, 0, 1, 7, 2, 6, 9, 9, 3, 5, 1, 5, 9, 7, 1, 1, 3, 6, 8, 9,\n",
              "        4, 8, 2, 1, 4, 2, 3, 1, 0, 2, 7, 0, 0, 0, 4, 6, 3, 3, 0, 5, 1, 6, 2, 1,\n",
              "        4, 6, 2, 7, 2, 4, 3, 4, 7, 5, 6, 2, 7, 6, 0, 5, 4, 0, 2, 9, 5, 3, 5, 4,\n",
              "        5, 8, 0, 4, 0, 4, 3, 0, 0, 0, 2, 9, 9, 6, 3, 5, 6, 3, 1, 2, 4, 6, 2, 9,\n",
              "        6, 8, 1, 8, 9, 2, 3, 6, 8, 4, 1, 8, 8, 8, 8, 7, 9, 3, 4, 1, 7, 0, 5, 6,\n",
              "        2, 2, 3, 3, 2, 2, 7, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M43RnGRSDUPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now we need to evualuate our model by doing the element wise comparision\n",
        "def accuracy(output,label):\n",
        "  max_probs,index=torch.max(output,dim=1)\n",
        "  return torch.tensor(torch.sum(preds==label).item()/len(preds))\n"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCu60zEmLyC0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7581ae8c-605b-4f1f-ab37-2cf6c9735a4c"
      },
      "source": [
        "accuracy(outputs,labels)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0625)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfL_dNBZFcmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we will not provide the probability for comparision of actual with pred\n",
        "#we calculate the loss in the classification problems is cross entropy\n",
        "#we wont use gradient descent because pred output is not differentiable\n",
        "#cross entropy is the negative log of predicted prob of the corrected label averged over all the training samples\n",
        "loss_fn=F.cross_entropy"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYB6Z81ZGzKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss for current batch of data\n",
        "loss=loss_fn(outputs,labels)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWstiFhuIso9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47ce0ec2-5445-44ce-c401-938104b17cbe"
      },
      "source": [
        "print(loss)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3247, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K0X5XPRNBey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3b30ed07-861f-4060-8635-b44ac14d656d"
      },
      "source": [
        "#Now we are going to train the model \n",
        "#this will be indentical to the linear regression\n",
        "'''\n",
        "for ep in range(epoch):\n",
        "  for batch in tr_load:\n",
        "    #model prediction\n",
        "    #calculate loss\n",
        "    #calculate gradients\n",
        "    #update the parameters(weights and biases) using gradients\n",
        "    #reset the gradients \n",
        "\n",
        "  \n",
        "  for batch in val_load:\n",
        "    #model prediction\n",
        "    #calculate loss \n",
        "    #generate metrics(accuracy) \n",
        " #calculate average loss and metrics\n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      '''"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef fit(epoch,model,loss,opt,train):\\n  for ep in range(epoch):\\n    for batch in tr_load:\\n      #model prediction\\n      #calculate loss\\n      #calculate gradients\\n      #update the parameters(weights and biases) using gradients\\n      #reset the gradients '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEOoQ2OrOmaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}